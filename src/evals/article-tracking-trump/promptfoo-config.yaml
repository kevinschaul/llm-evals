# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json
description: "Trump storylines"

prompts:
  - Is this article primarily about a new action or announcement by the Trump administration/White House/Executive? Respond simply with "true" or "false".\n{{headline}}\n{{content}}
  # - Is this about Trump? "true" or "false" .\n{{headline}}\n{{content}}

providers:
  - id: "http://127.0.0.1:4242/eval"
    label: "openai/gpt-4o-mini"
    config:
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "openai/gpt-4o-mini"
            transform_func: parse_boolean

  - id: "http://127.0.0.1:4242/eval"
    label: "qwen/qwen3-14b"
    config:
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "qwen/qwen3-14b"
            transform_func: parse_boolean

  - id: "http://127.0.0.1:4242/eval"
    label: "google/gemma-3-12b"
    config:
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "google/gemma-3-12b"
            transform_func: parse_boolean

  - id: "http://127.0.0.1:4242/eval"
    label: "anthropic/claude-sonnet-4-0"
    config:
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "anthropic/claude-sonnet-4-0"
            transform_func: parse_boolean

  - id: "http://127.0.0.1:4242/eval"
    label: "anthropic/claude-opus-4-0"
    config:
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "anthropic/claude-opus-4-0"
            transform_func: parse_boolean

  - id: "http://127.0.0.1:4242/eval"
    label: "qwen3-235b-a22b-2507"
    config:
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "openrouter/qwen/qwen3-235b-a22b-2507"
            options:
              provider:
                quantizations:
                  - "fp8"
            transform_func: parse_boolean

  - id: "http://127.0.0.1:4242/eval"
    label: "deepseek-v3-0324"
    config:
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "openrouter/deepseek/deepseek-chat-v3-0324"
            options:
              provider:
                quantizations:
                  - "fp8"
            transform_func: parse_boolean

  - id: "http://127.0.0.1:4242/eval"
    label: "openai/gpt-oss-20b"
    config:
      transformResponse: 'file://../../../catchErrors.js'
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "openrouter/openai/gpt-oss-20b"
            options:
              provider:
                only:
                  - "nebius/fp4"
            transform_func: parse_boolean

  - id: "http://127.0.0.1:4242/eval"
    label: "openai/gpt-oss-120b"
    config:
      transformResponse: 'file://../../../catchErrors.js'
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "openrouter/openai/gpt-oss-120b"
            options:
              provider:
                only:
                  - "nebius/fp4"
                  - "fp4"
            transform_func: parse_boolean

tests: file://tests.csv

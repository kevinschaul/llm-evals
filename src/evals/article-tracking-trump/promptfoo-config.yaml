# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json
description: "Trump storylines"

prompts:
  - Is this article primarily about a new action or announcement by the Trump administration/White House/Executive? Respond simply with "true" or "false".\n{{headline}}\n{{content}}
  # - Is this about Trump? "true" or "false" .\n{{headline}}\n{{content}}

providers:
  - id: "http://127.0.0.1:4242/eval"
    label: "openai/gpt-4o-mini"
    config:
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "openai/gpt-4o-mini"
            transform_func: parse_boolean

  # - id: "http://127.0.0.1:4242/eval"
  #   label: "wapo"
  #   config:
  #     method: POST
  #     body:
  #       prompt: "{{prompt}}"
  #       options:
  #         config:
  #           model: "wapo"
  #           transform_func: parse_boolean

  - id: "http://127.0.0.1:4242/eval"
    label: "qwen3:14b:IQ4_XS"
    config:
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "hf.co/unsloth/Qwen3-14B-GGUF:IQ4_XS"
            transform_funcs:
              - strip_think_tags
              - parse_boolean

  - id: "http://127.0.0.1:4242/eval"
    label: "gemma3:12b:Q4_0"
    config:
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "hf.co/unsloth/gemma-3-12b-it-GGUF:Q4_0"
            transform_func: parse_boolean

  - id: "http://127.0.0.1:4242/eval"
    label: "anthropic/claude-sonnet-4-0"
    config:
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "anthropic/claude-sonnet-4-0"
            transform_func: parse_boolean

  - id: "http://127.0.0.1:4242/eval"
    label: "anthropic/claude-opus-4-0"
    config:
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "anthropic/claude-opus-4-0"
            transform_func: parse_boolean

  - id: "http://127.0.0.1:4242/eval"
    label: "qwen3-235b-a22b-2507"
    config:
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "openrouter/qwen/qwen3-235b-a22b-2507"
            options:
              provider:
                quantizations:
                  - "fp8"
            transform_func: parse_boolean

  - id: "http://127.0.0.1:4242/eval"
    label: "deepseek-v3-0324"
    config:
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "openrouter/deepseek/deepseek-chat-v3-0324"
            options:
              provider:
                quantizations:
                  - "fp8"
            transform_func: parse_boolean

tests: file://tests.csv

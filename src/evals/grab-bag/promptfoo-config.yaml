# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json
description: "Grab bag"

prompts:
  - "{{prompt}}"

providers:
  - id: "http://127.0.0.1:4242/eval"
    label: "openai/gpt-4o-mini"
    config:
      transformResponse: 'file://../../../catchErrors.js'
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "openai/gpt-4o-mini"

  - id: "http://127.0.0.1:4242/eval"
    label: "openai/gpt-4o"
    config:
      transformResponse: 'file://../../../catchErrors.js'
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "openai/gpt-4o"

  - id: "http://127.0.0.1:4242/eval"
    label: "gemini-2.5-pro-preview-03-25"
    config:
      transformResponse: 'file://../../../catchErrors.js'
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "gemini-2.5-pro-preview-03-25"

  - id: "http://127.0.0.1:4242/eval"
    label: "qwen/qwen3-14b"
    config:
      transformResponse: 'file://../../../catchErrors.js'
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "qwen/qwen3-14b"

  - id: "http://127.0.0.1:4242/eval"
    label: "google/gemma-3-12b"
    config:
      transformResponse: 'file://../../../catchErrors.js'
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "google/gemma-3-12b"

  - id: "http://127.0.0.1:4242/eval"
    label: "gemma-3-27b-it"
    config:
      transformResponse: 'file://../../../catchErrors.js'
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "gemma-3-27b-it"

  - id: "http://127.0.0.1:4242/eval"
    label: "anthropic/claude-3-opus-20240229"
    config:
      transformResponse: 'file://../../../catchErrors.js'
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "anthropic/claude-3-opus-20240229"

  - id: "http://127.0.0.1:4242/eval"
    label: "anthropic/claude-3-5-sonnet-20241022"
    config:
      transformResponse: 'file://../../../catchErrors.js'
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "anthropic/claude-3-5-sonnet-20241022"

  - id: "http://127.0.0.1:4242/eval"
    label: "anthropic/claude-3-7-sonnet-20250219"
    config:
      transformResponse: 'file://../../../catchErrors.js'
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "anthropic/claude-3-7-sonnet-20250219"

  - id: "http://127.0.0.1:4242/eval"
    label: "anthropic/claude-sonnet-4-0"
    config:
      transformResponse: 'file://../../../catchErrors.js'
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "anthropic/claude-sonnet-4-0"

  - id: "http://127.0.0.1:4242/eval"
    label: "anthropic/claude-opus-4-0"
    config:
      transformResponse: 'file://../../../catchErrors.js'
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "anthropic/claude-opus-4-0"

  - id: "http://127.0.0.1:4242/eval"
    label: "lmstudio/openai/gpt-oss-20b"
    config:
      transformResponse: 'file://../../../catchErrors.js'
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "openai/gpt-oss-20b"

  - id: "http://127.0.0.1:4242/eval"
    label: "openai/gpt-oss-20b"
    config:
      transformResponse: 'file://../../../catchErrors.js'
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "openrouter/openai/gpt-oss-20b"
            options:
              provider:
                quantizations:
                  - "fp4"

  - id: "http://127.0.0.1:4242/eval"
    label: "openai/gpt-oss-120b"
    config:
      transformResponse: 'file://../../../catchErrors.js'
      method: POST
      body:
        prompt: "{{prompt}}"
        options:
          config:
            model: "openrouter/openai/gpt-oss-120b"
            options:
              provider:
                quantizations:
                  - "fp4"

tests: https://docs.google.com/spreadsheets/d/1mr8K_IP4yJP_cAHGm_OsQXwJg_7WpqchgMbvMpAuCdM/edit?gid=0

prompts: prompts.csv
models: models.csv
tests: tests.csv
transform_func: transform_output.py

cache_dir: cached-llm-responses
output_dir: results
